[checkpoints]
global_output_folder = ./train_output
base_name = celeba_libstick
interval_checkpoint = 20
interval_figure = 20

[training]
beta_IB = 1.0000
n_epochs = 800
# whether to use exponential or 'milestone' lr decay
exponential_scheduler = False
scheduler_milestones = [200, 400, 600]
clip_grad_norm = 2.0
optimizer = ADAM
lr = 5e-5
# lr = 1e-6

[data]
batch_size = 32
dataset = celeba
# label_smoothing = 0.01
label_smoothing = 0.0
celeb_label = 36
resolution = 64

# | label | title               | dist.    |
# |    36 | Wearing_Lipstick    |   16859 | 56.1967   |
# |    21 | Mouth_Slightly_Open |   14139 | 47.13     |
# |    31 | Smiling             |   14092 | 46.9733   |
# |    19 | High_Cheekbones     |   13847 | 46.1567   |
# |    18 | Heavy_Makeup        |   13708 | 45.6933   |

[model]
# glow=False
# K=32
# L=3
